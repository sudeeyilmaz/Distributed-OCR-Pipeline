# ğŸ” FastAPI Async OCR Service

![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-High%20Performance-009688)
![Celery](https://img.shields.io/badge/Celery-Async%20Tasks-green)
![MySQL](https://img.shields.io/badge/MySQL-Database-4479A1)
![Docker](https://img.shields.io/badge/Docker-Containerized-2496ED)

A robust, **asynchronous Optical Character Recognition (OCR) microservice** designed to extract text from various media formats. Built with **FastAPI** for the REST interface and **Celery** for handling heavy background processing tasks (like video parsing).

This project is fully containerized using **Docker**, making it easy to deploy and scale.

## ğŸš€ Key Features

* **ğŸ“· Image OCR:** Extracts text from standard image formats (`.jpg`, `.png`).
* **ğŸ¥ Video OCR:** Processes video files by extracting frames at specified intervals and performing OCR on them asynchronously.
* **ğŸ“‚ Batch Processing:** Scans entire folders to process multiple media files in the background.
* **âš¡ Asynchronous Architecture:** Uses **Celery** workers to handle long-running tasks without blocking the main API thread.
* **ğŸ” Searchable Database:** All extracted text and media metadata are indexed in **MySQL**, allowing users to perform complex queries and text searches.
* **ğŸ³ Docker Ready:** Includes `docker-compose` for one-command orchestration of the API, Workers, and Database.

## ğŸ› ï¸ Tech Stack

* **Framework:** FastAPI (Python)
* **Task Queue:** Celery
* **Broker:** Redis (via Docker)
* **Containerization:** Docker & Docker Compose
* **OCR Engine:** Tesseract (Integrated in Worker)
* **Database:** MySQL (managed via `ocr_db.py`)

## ğŸ“‚ Project Structure
```
text
â”œâ”€â”€ ocr_fastapi.py      # Main API Gateway (Routes)
â”œâ”€â”€ tasks.py            # Celery Worker Tasks (Image/Video Processing)
â”œâ”€â”€ ocr_db.py           # MySQL Database Connection & Queries
â”œâ”€â”€ ocr_schemas.py      # Pydantic Models for Data Validation
â”œâ”€â”€ docker-compose.yml  # Orchestration Config
â”œâ”€â”€ Dockerfile          # Container Definition
â””â”€â”€ requirements.txt    # Dependencies
```
## âš™ï¸ Installation & Usage
Since the project is containerized, the easiest way to run it is via Docker.

**1. Clone the repository**
```bash
git clone [https://github.com/sudeeyilmaz/Distributed-OCR-Pipeline.git](https://github.com/sudeeyilmaz/Distributed-OCR-Pipeline.git)
cd Distributed-OCR-Pipeline
```
**2. Build and Run with Docker**
```bash
docker-compose up --build
```
This command starts the FastAPI server, Celery workers, and the Redis broker.

**3. Access the API**
Once running, the API is accessible at:
API Root: http://localhost:8003
``` bash
Swagger Documentation: http://localhost:8003/docs
```
## ğŸ—ï¸ How It Works (Architecture)
**1.** Client sends a request (e.g., upload video) to FastAPI.

**2.** FastAPI saves the file and pushes a task to the Celery/Redis Queue.

**3.** Celery Worker picks up the task, processes the video frame-by-frame using OCR, and saves the text results to the Database.

**4.**  Data Persistence: The worker connects to MySQL via ocr_db.py to save the extracted text and metadata.

**5.** Client can poll /task_status to check progress or use /query to search the results once finished.
